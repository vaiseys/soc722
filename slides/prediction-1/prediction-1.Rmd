---
title: "Prediction<br><small>Part I</small>"
author: "Stephen Vaisey<br>Professor of Sociology and Political Science<br>Duke University"
date: "Fall 2019<br><br><small>`r icon::fa_link()` <a href='stephenvaisey.com'><font color='F3F2F1'>stephenvaisey.com</font></a><br>`r icon::fa_twitter()` <a href='http://twitter.com/vaiseys'><font color='F3F2F1'>@vaiseys</font></a><br>`r icon::fa_github()` <a href='https://github.com/vaiseys'><font color='F3F2F1'>@vaiseys</font></a></small> "
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: ["left", "middle", "inverse"]
---

```{r setup, echo=FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, fig.align = 'center', fig.width = 6, fig.asp = .618 , out.width = "80%", fig.retina = 3 , dev = 'svg')

options(knitr.table.format = "html")

library(here)
library(tidyverse)
theme_set(theme_minimal())

```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
mono_light(
  base_color = "#00539B" ,
  white_color = "#F3F2F1" ,
  black_color = "#262626" ,
  text_font_size = "30px" ,
  code_font_size = ".9em" ,
  code_font_family = "Input" ,
  header_color = "#C84E00" ,
  text_slide_number_font_size = "0.6em" ,
  code_highlight_color = "rgba(161,183,13,0.5)" ,
  link_color = "#993399" ,
  extra_css = list(".remark-slide-content" = list("padding-top" = "13px")))

```


# Homework debrief

Ask **two questions** about the concepts


---

# Prediction and explanation

- Unlike political scientists who try to forecast elections, sociologists are 
rarely trying to predict future events

- The prediction weâ€™re generally interested in is prediction of patterns 
outside the sample (i.e., **generalization**)

- **Out-of-sample prediction** is a stronger test of understanding than in-sample prediction

---

# Example: Fragile Families Challenge (2017)

```{r}
knitr::include_graphics("https://vaiseys.github.io/soc722/images/ffchallenge.png")

```

---

# Results (less error is better)

```{r, out.width="70%"}
knitr::include_graphics("https://vaiseys.github.io/soc722/images/ffchallenge-results.png")

```

---

# Today's agenda

1. Review of correlation

2. Linear regression model

3. Regression to the mean

4. Additional examples

---
class: center, middle, inverse

# 1. Review of correlation

---

# Correlation (Pearson's _r_ )

$~$

$$r = \frac{1}{n-1}\sum^n_{i=1} \left( \frac{x_i-\bar{x}}{S_x}\times\frac{y_i-\bar{y}}{S_y} \right)$$

$~$

In other words, it's the average of the product of two variables' z-scores. It's a measure of how strongly two variables are associated.

---

# Correlation

- On average, how do two variables move together

- Positive (negative) correlation: When x is larger than its mean, y is likely (unlikely) to be larger than its mean

- Positive (negative) correlation: data cloud slopes up (down)

- High correlation: data cluster tightly around a line

---

# Visualizing different correlations

```{r diffcorrs}
# make a function that makes fake data with a given correlation
mkdata <- function(n, r) {
  result <- 
    MASS::mvrnorm(n, 
                  mu = c(0,0), 
                  Sigma = matrix(c(1,r, r,1) , 
                            nrow = 2 ,
                            dimnames = list(c("y","x"))) ) %>% 
    as_tibble() %>% 
    mutate( corr = r )
  return( result )
}

# for reproducibility
set.seed(0903)

# make four different versions
cdata <- bind_rows( mkdata( 1000 ,  0 ) ,
                    mkdata( 1000 , .3 ) ,
                    mkdata( 1000 , .6 ) ,
                    mkdata( 1000 , .9 ))

# plot the result
ggplot( cdata , aes( x = x, y = y )) +
  geom_point( alpha = .3 ) +
  facet_wrap( ~factor(corr) ) 


```


---

# Warning! 

## Correlation only makes sense for continuous(ish) variables!

---

# Anscombe's quartet

```{r anscombe}
data("anscombe")
d <- panelr::long_panel(anscombe, begin = 1, end = 4, wave = "set")

ggplot( d , aes( x = x , y = y  )) +
  geom_point( alpha = .5 , aes( color = factor( set ) ) ) +
  geom_line( stat = "smooth" , method = "lm" , alpha = .3  ) +
  facet_wrap(~set) +
  theme(legend.position = "none")

```


---

# Correlations: 2011 Gapminder data

```{r, echo = TRUE}
data( gapminder , package = "dslabs" )
gm2011 <- gapminder %>% 
  filter( year == 2011 ) %>% 
  drop_na()

```

---

# Correlation matrix

```{r, echo = TRUE}
corrr::correlate( 
  select( gm2011,
          infant_mortality, 
          life_expectancy,
          fertility ) ,
  diagonal = 1 ) %>% 
  knitr::kable( digits = 3 )

```

---

# Scatterplot matrix

```{r scatmat}
library(GGally)

ggpairs( 
  select( gm2011,
          infant_mortality, 
          life_expectancy,
          fertility ) ,
  lower = list(continuous = wrap("points", alpha = 0.3) )
)

```

---
class: center, middle, inverse

# 2. Linear Regression Model

---

# Where do we draw the line?

```{r scatter}
ggplot( gm2011 , aes( x = life_expectancy , y = fertility , color = continent ) ) +
  geom_point( alpha = .5 ) +
  labs( title = "Life Expectancy and Fertility in 185 countries, 2011" ,
        x = "Life Expectancy in Years" ,
        y = "Average # of children per woman" , 
        color = "Continent")

```

---

# Linear regression model

$$Y = \alpha + \beta X + \varepsilon$$

<small>

| Symbol|  Meaning |
|:------|---------:|
| $Y$ | outcome variable |
| $X$ | predictor variable |
| $\alpha$, $\beta$ | parameters of the model |
| $\varepsilon$ | unobserved random error |
| | |
| $\alpha+\beta X$ | expected mean of $Y$ given a value of $X$  |
| $\alpha$ | expected value of $Y$ when $X=0$ |
| $\beta$ | expected change in $Y$ given 1-unit increase in $X$ |

</small>

---

# The regression line

```{r regline}
ggplot( gm2011 , aes( x = life_expectancy , y = fertility ) ) +
  geom_point( alpha = .5 , aes( color = continent ) ) +
  geom_line( stat = "smooth" , method = "lm" , color = "#262626" , alpha = .7 ) +
  labs( title = "Life Expectancy and Fertility in 185 countries, 2011" ,
        x = "Life Expectancy in Years" ,
        y = "Average # of children per woman" , 
        color = "Continent")

```

---

# Getting the equation

```{r, echo = TRUE}
fit1 <- lm( fertility ~ life_expectancy ,
            data = gm2011 )
fit1

```

---

# Regression as a *model*

fertility $= 12.4 -.13 \times$life_expectancy $+ \text{ }\varepsilon$

--

From 370 pieces of information (185 $\times$ 2) to just two pieces: **slope** and 
**intercept**

--

So what's a good guess for a country with a life expectancy of 80 years?

--

.center[The answer is **2**!]

---

# Why _this_ line?

### Estimate the model parameters from the data
$(\hat{\alpha},\hat{\beta})$ are estimated coefficients <br>
$\hat{Y} = \hat{\alpha}+\hat{\beta}X$ are fitted/predicted values <br>
$\hat{\varepsilon} = Y - \hat{Y}$ are estimated residuals

### We obtain these estimates via least squares

That is, minimizing $SSR = \sum\hat{\varepsilon_i}^2$ or $RMSE= \sqrt{\frac{SSR}{n}}$

---

# Some algebra for least squares

### Estimated coefficients in mathematical expressions:

$$\hat{\beta} = \frac{\sum(Y_i - \bar{Y}) (X_i - \bar{X})} {\sum(X_i - \bar{X})}$$

$$\hat{\alpha} = \bar{Y} - \hat{\beta}\bar{X} $$

--

### Relationship between slope and correlation

$$\hat{\beta} = corr(Y,X) \times \frac{S_y}{S_x} $$

---

# How well does the model fit?

### In other words, how well does it predict the outcome?

$~$

$$R^2 = 1 - \frac{SSR}{TSS} = 1-\frac{\sum \hat{\varepsilon}_i^2}{\sum(Y_i - \bar{Y})}$$

.footnote[This is the correlation coefficient (_r_) squared. Here's that's about
.76. You could say "differences in life expectancy account for 76% of the 
variance in fertility." But remember, this is **descriptive**, not **causal**.]

---

# More examples if time permits

---
class: middle, center, inverse

# 3. Regression to the mean

---

# Galton and regression to the mean

```{r, out.width = "50%"}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/b/b2/Galton%27s_correlation_diagram_1875.jpg")

```

???

Kahneman example of Israeli fighter pilots
Praise -> worse performance
Criticism -> better performance

---

# Galton and regression to the mean

The correlation between parent and child's height is about .46 in Galton's 
data. The mean height is (about) 69 inches (5'9"). If a man is 79 inches tall 
(6'7"), how tall can he expect his male children to be? What about his male 
grandchildren?

--

**Children** &nbsp;&nbsp;&nbsp;&nbsp; $69 + 10\times.46 \approx 73.6$ inches
(almost 6'2")

--

**Grandchildren**  &nbsp;&nbsp;&nbsp;&nbsp; $69 + 10\times.46^2 \approx 71.1$ 
inches (about 5'11")

--

In other words, you get to "keep" about $r \times 100$ percent of your "above-
averageness" at each generation.

???

Galton multiplied female heights by 1.08 to make them comparable

---
class: inverse, center, middle

# 4. Additional examples

---

# Occupational mobility in the United States

```{r, out.width="95%"}
knitr::include_graphics("https://vaiseys.github.io/soc722/images/hout-mobility.jpg")

```

.footnote[<small>Michael Hout. 2018. Americans' occupational status reflects the status 
of both of their parents. _PNAS_ 115 (38) 9527-9532.</small>]




